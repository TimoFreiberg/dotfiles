---
id: 8c215b54
title: "pi hashline"
tags: []
status: open
created_at: "2026-02-16T10:05:24.197Z"
---

Now I have a good picture of both the blog post and pi's current edit infrastructure. Here's my analysis:

 What Hashline Proposes

 Instead of the current str_replace approach (model reproduces oldText verbatim, harness finds and replaces it), the model gets
 tagged output from read/grep:

 ```
   11:a3|function hello() {
   22:f1|  return "world";
   33:0e|}
 ```

 Then edits reference tags: "replace line 2:f1", "replace range 1:a3 through 3:0e", "insert after 3:0e". No need to reproduce old
 content. Hashes act as staleness checks — if the file changed since the last read, hashes won't match.

 How Promising Is It?

 Strong points:
 - The blog's benchmark results are compelling: some models see massive improvements (Grok Code Fast 1: 6.7% → 68.3%), and even
 strong models gain 5-14 points
 - Output tokens drop significantly (~20-61%) because the model stops burning tokens reproducing old content and retrying
 - Pi's current str_replace has the exact failure modes described: "String to replace not found" when the model gets
 whitespace/indentation wrong, and multiple-match rejections
 - The existing fuzzy matching in edit-diff.ts (smart quotes, trailing whitespace normalization) is essentially a band-aid for the
 core problem hashline addresses

 Risks:
 - The benchmark uses the author's own fork with his own system prompts tuned for the format. Results may not transfer directly
 - Models haven't been trained on this format — relies entirely on in-context learning from the tool description/system prompt.
 Works today, but fragile across model updates
 - 2-3 char hashes (256-4096 values) will have collisions on lines with identical content. Line numbers disambiguate, but the
 model needs to get both right
 - More output tokens from read/grep (every line gets a linenum:hash| prefix — ~6-8 chars per line)
 - The edit tool schema becomes more complex: need to support replace-line, replace-range, insert-after, possibly delete
 operations

 Implementation Difficulty

 Medium-high effort. Here's what would change:

 1. read.ts — Moderate: Add a line-hashing pass to text output. Each line gets linenum:hash| prefix. Need a fast hash function
 (e.g., take 2 bytes of a CRC or FNV hash, hex-encode).
 2. grep.ts — Moderate: Same line tagging in match output. Currently outputs file:line: content, would need file:line:hash|
 content.
 3. edit.ts — Major rewrite: Completely different input schema. Instead of {path, oldText, newText}, something like {path,
 operations: [{type: "replace_range", startLine, startHash, endLine, endHash, newText}, ...]}. The matching logic changes from
 string search to line-number + hash verification.
 4. edit-diff.ts — Moderate: The fuzzy matching infrastructure becomes largely unnecessary. Diff generation logic stays but
 anchoring changes.
 5. System prompt — Needs clear explanation of the hashline format and edit operations.
 6. TUI diff preview — The computeEditDiff function in edit-diff.ts is used for live preview rendering; needs adaptation to the
 new schema.
 7. Extensions — The EditOperations interface changes, breaking any extensions that override edit behavior.

 My Recommendation

 It's worth experimenting with, but I'd suggest a gradual approach:

 1. Phase 1: Add hashline tags to read output only (low risk, easily reversible). Measure token overhead.
 2. Phase 2: Build a new hashline_edit tool alongside the existing edit tool. Test both, compare failure rates across models.
 3. Phase 3: If results are positive, make it the default and deprecate the old edit.

 The biggest unknown is whether the models pi supports (Claude, GPT, Gemini, Grok, etc.) will reliably produce the hashline edit
 format from just a tool description, without fine-tuning. The blog author's benchmark suggests yes, but it's worth validating in
 pi's specific context with pi's system prompts.

 Want to move forward with any of this, or discuss specific aspects further?
